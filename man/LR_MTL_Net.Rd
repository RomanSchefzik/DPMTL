% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/local_withDP_LR_Net.R
\name{LR_MTL_Net}
\alias{LR_MTL_Net}
\title{Solver of MTL with logistic loss and network incorporation}
\usage{
LR_MTL_Net(X, Y, lam, C, G, opts)
}
\arguments{
\item{X}{A set of feature matrices}

\item{Y}{A set of binary responses \eqn{\in\{1, -1\}}}

\item{lam}{The hyper-parameter controlling the sparsity}

\item{C}{The hyper-parameter associated with L2 term}

\item{G}{Matrix describing the task relatedness}

\item{opts}{A list of options controlling the optimization procedure and specifying the differential privacy component. See Details.}
}
\value{
The converged result of optimization
}
\description{
Solver of MTL with logistic loss and network incorporation
}
\details{
Solver of MTL with logistic loss and network incorporation. \cr A list of options controlling the optimization procedure and specifying the differential privacy component based on a privacy parameter epsilon>0 can be provided via the \code{opts} argument:
\itemize{
\item{\code{init} \cr A value (0 or 1) specifying the starting point of the involved gradient descent algorithm. Specifically, two options are provided: A value of 0 (default) uses the 0 matrix as starting point, while a value of 1 uses a starting point specified by the user. If applicable (i.e., \code{init=1}), the user-defined starting point (matrix) has to be specified via the \code{w0} argument in \code{opts}.}
\item{\code{w0} \cr A user-defined starting point (matrix) for the involved gradient descent algorithm, in case \code{init=1} is specified (otherwise, for \code{init=0}, the value is set to NULL, the default).}
\item{\code{tol} \cr A value >0 specifying the tolerance of the acceptable precision of solution to terminate the algorithm. Default value is set to 0.01.}
\item{\code{maxIter} \cr A value >0 specifying the maximum number of iterations. Default value is set to 50.}
\item{\code{ter} \cr A value (1, 2 or 3) specifying one out of three termination rules to determine whether the optimization converges. The first rule (\code{ter=1}) checks whether the current objective value is close enough to 0. The second rule (\code{ter=2}) considers the last two objective values and checks whether the decrement is close enough to 0 (default). The third rule (\code{ter=3}) allows the optimization to be performed for a certain maximum number of iterations (\code{maxIter}).}
\item{\code{diffPrivEpsilon} \cr A value >0 serving as a privacy parameter to control the degree of differential privacy. Setting the value to NULL (default) means that no differential privacy is included.}
\item{\code{nRunsSensitAn} \cr A value >0 specifying the number of simulation runs for the respective sensitivity analyses in case a differential privacy component is included. Default value is set to 100 (only effective if a corresponding value for \code{diffPrivEpsilon} is provided; otherwise, no differential privacy is included).}
}
}
\examples{
set.seed(24)
X0<-list(matrix(rnorm(100000),nrow=200,ncol=500),matrix(rnorm(150000),nrow=300,ncol=500))
set.seed(24)
Y0<-list(sample(c(1,-1),200,replace=TRUE),sample(c(1,-1),300,replace=TRUE))
lam0<-0.05
C0<-1
G0<-diag(2)-(1/2)
#non-private model
opts0<-list(init=0,w0=NULL,tol=0.01,maxIter=50,ter=2,diffPrivEpsilon=NULL,nRunsSensitAn=NULL)
model.nonprivate<-LR_MTL_Net(X=X0,Y=Y0,lam=lam0,C=C0,G=G0,opts=opts0)
#example for a private model
opts1<-list(init=0,w0=NULL,tol=0.01,maxIter=50,ter=2,diffPrivEpsilon=0.7,nRunsSensitAn=100)
set.seed(24)
model.private<-LR_MTL_Net(X=X0,Y=Y0,lam=lam0,C=C0,G=G0,opts=opts1)

}
